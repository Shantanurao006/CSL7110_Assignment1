# CSL7110 Assignment 1
## Hadoop MapReduce â€“ WordCount Implementation

---

## ğŸ‘¨â€ğŸ“ Student Details
Name: Shantanu Rao  
Roll Number: <M24DE2026>

---

## ğŸ“Œ Objective
Install Hadoop locally and implement the WordCount program using MapReduce framework.

---

## ğŸ›  Technologies Used
- Hadoop 3.3.6
- Java 8
- Ubuntu (WSL)
- HDFS
- Git & GitHub

---

## ğŸ“‚ Project Structure

CSL7110/
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ WordCount.java
â”œâ”€â”€ classes/
â”œâ”€â”€ WordCount.jar
â”œâ”€â”€ 200.txt
â””â”€â”€ README.md

---

## ğŸš€ Steps to Run the Program

### 1ï¸âƒ£ Start Hadoop

start-dfs.sh

Check:

jps

Expected:
NameNode
DataNode
SecondaryNameNode

---

### 2ï¸âƒ£ Upload file to HDFS

hdfs dfs -mkdir -p /user/student
hdfs dfs -put 200.txt /user/student/

Check:

hdfs dfs -ls /user/student

---

### 3ï¸âƒ£ Run WordCount

hadoop jar WordCount.jar WordCount /user/student/200.txt output

---

### 4ï¸âƒ£ View Output

hdfs dfs -cat output/part-r-00000

---

## â± Execution Time Measurement

Run with timing:

time hadoop jar WordCount.jar WordCount /user/student/200.txt output

Note the real time displayed.

---

## ğŸ“Š Performance Experiment

We tested different split sizes:

Default run:
time hadoop jar WordCount.jar WordCount /user/student/200.txt output1

Run with custom split size:

hadoop jar WordCount.jar WordCount \
-D mapreduce.input.fileinputformat.split.maxsize=1048576 \
/user/student/200.txt output2

Compare execution times.

Observation:
Smaller split size increases number of mappers and may affect performance.

---

## ğŸ§  Understanding Mapper and Reducer

### Mapper
- Reads input line
- Cleans text
- Emits (word, 1)

### Reducer
- Receives grouped words
- Adds all counts
- Outputs (word, total_count)

---

